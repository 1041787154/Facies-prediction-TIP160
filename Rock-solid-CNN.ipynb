{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating a CNN to analyse Facies data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the research in the following article: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import feature_column\n",
    "from tensorflow.keras import layers, models\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "from statistics import mean\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, normalization, Convolution1D\n",
    "from keras.callbacks import History\n",
    "from keras.utils import np_utils\n",
    "from keras.callbacks import History\n",
    "from sklearn import metrics\n",
    "from classification_utilities import display_cm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data and replace missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "\n",
    "facies_data = pd.read_csv('./datasets/facies_vectors.csv')\n",
    "test_data = pd.read_csv('./datasets/validation_data_with_facies_new.csv')\n",
    "X_test = test_data.drop('Facies', axis=1)\n",
    "y_test = test_data['Facies']\n",
    "\n",
    "X_test = X_test.drop('Unnamed: 0', axis=1)\n",
    "\n",
    "# Parameters\n",
    "\n",
    "non_feature_columns = ['Formation', 'Well Name', 'Depth']\n",
    "feature_names = ['Facies', 'Formation', 'Well Name', 'Depth', 'GR', 'ILD_log10', 'DeltaPHI', 'PHIND', 'PE', 'NM_M', 'RELPOS']\n",
    "facies_names = ['SS', 'CSiS', 'FSiS', 'SiSh', 'MS', 'WS', 'D', 'PS', 'BS']\n",
    "facies_colors = ['#F4D03F', '#F5B041','#DC7633','#6E2C00', '#1B4F72','#2E86C1', '#AED6F1', '#A569BD', '#196F3D']\n",
    "\n",
    "# Fill 'PE' missing values with mean\n",
    "if facies_data['PE'].isnull().any():\n",
    "    facies_data['PE'] = facies_data['PE'].fillna(value=facies_data['PE'].mean())\n",
    "\n",
    "# Store features and labels\n",
    "train = facies_data #.drop(non_feature_columns, axis=1)\n",
    "\n",
    "test = test_data #.drop(non_feature_columns, axis=1)\n",
    "\n",
    "# Store well labels and depths\n",
    "well = facies_data['Well Name']\n",
    "depth = facies_data['Depth']\n",
    "\n",
    "\n",
    "#train = pd.DataFrame(imp.transform(train), columns=feature_names)\n",
    "#validate = pd.DataFrame(imp.transform(validate), columns=feature_names)\n",
    "#test = pd.DataFrame(imp.transform(test), columns=feature_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((830, 10), (830,), (4149, 11))"
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape, y_test.shape, train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Convert facies class to one-hot-vector representation\n",
    "num_classes = train['Facies'].unique().size\n",
    "y_train = np_utils.to_categorical(train['Facies'].values-1, num_classes)\n",
    "\n",
    "# Window around central value and define the seven features we are using\n",
    "window_width = 15\n",
    "feature_list = ['GR', 'ILD_log10', 'DeltaPHI', 'PHIND', 'PE', 'NM_M', 'RELPOS']\n",
    "X_train = prepare_feature_vectors(train, feature_list, window_width)\n",
    "X_test = prepare_feature_vectors(test, feature_list, window_width)\n",
    "\n",
    "num_train_samples = np.asarray(np.shape(X_train))[0]\n",
    "num_test_samples = np.asarray(np.shape(X_test))[0]\n",
    "\n",
    "print('Training Samples=', num_train_samples, '   Test Samples=', num_test_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define neural network to classify facies\n",
    "num_filters = 12\n",
    "dropout_prob = 0.6\n",
    "\n",
    "convnet = Sequential()\n",
    "convnet.add(Convolution1D(num_filters, 1, border_mode='valid',\n",
    "                          input_shape=(window_width, len(feature_list))))\n",
    "convnet.add(Activation('relu'))\n",
    "convnet.add(Convolution1D(7, 1, border_mode='valid'))\n",
    "convnet.add(Activation('relu'))\n",
    "convnet.add(Convolution1D(num_filters, 3, border_mode='valid'))\n",
    "convnet.add(Activation('relu'))\n",
    "convnet.add(Dropout(dropout_prob / 2))\n",
    "\n",
    "convnet.add(Flatten())\n",
    "convnet.add(Dense(4 * num_filters))\n",
    "convnet.add(normalization.BatchNormalization())\n",
    "convnet.add(Activation('sigmoid'))\n",
    "convnet.add(Dropout(dropout_prob))\n",
    "\n",
    "convnet.add(Dense(num_classes, activation='softmax'))\n",
    "convnet.compile(loss='categorical_crossentropy', optimizer='adadelta', metrics=['accuracy'])\n",
    "convnet.summary()\n",
    "\n",
    "# save initial weights\n",
    "initial_weights = convnet.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# define training parameters and prepare arrays to store training metrics\n",
    "epochs_per_fold = 1000\n",
    "num_fold = 6\n",
    "roll_stride = np.ceil(num_train_samples/num_fold).astype(int)\n",
    "\n",
    "convnet_hist = History()\n",
    "hist = np.zeros((4, num_fold, epochs_per_fold))\n",
    "f1scores = np.zeros(num_fold)\n",
    "y_test_ohv = np.zeros((num_test_samples, num_fold, num_classes))\n",
    "\n",
    "\n",
    "# shuffle input data\n",
    "#rand_perm = np.random.permutation(num_train_samples)\n",
    "#X_train = X_train[rand_perm]\n",
    "#Y_train = Y_train[rand_perm]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use 6-fold cross validation and train 6 neural networks, ending up with 6 sets of predictions\n",
    "for i in np.arange(num_fold):\n",
    "    convnet.set_weights(initial_weights)\n",
    "    X_train = np.roll(X_train, i*roll_stride, axis=0)\n",
    "    Y_train = np.roll(Y_train, i*roll_stride, axis=0)\n",
    "\n",
    "    convnet.fit(X_train, y_train, batch_size=200, epochs=epochs_per_fold, verbose=0,\n",
    "                validation_split=1.0/num_fold, callbacks=[convnet_hist])\n",
    "\n",
    "    hist[:, i, :] = [convnet_hist.history['accuracy'], convnet_hist.history['val_accuracy'],\n",
    "                     convnet_hist.history['loss'], convnet_hist.history['val_loss']]\n",
    "\n",
    "    Y_predict = 1 + np.argmax(convnet.predict(X_train), axis=1)\n",
    "    f1scores[i] = metrics.f1_score(1 + np.argmax(y_train, axis=1), Y_predict, average='micro')\n",
    "    print('F1 Score =', f1scores[i])\n",
    "\n",
    "    Y_test_ohv[:, i, :] = convnet.predict(X_test)\n",
    "    \n",
    "print('Average F1 Score =', np.mean(f1scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot callbacks\n",
    "hist = np.reshape(hist, (4, num_fold * epochs_per_fold))\n",
    "plt.plot(hist[0]); plt.plot(hist[1])\n",
    "plt.legend(['train', 'val'], loc='lower left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
